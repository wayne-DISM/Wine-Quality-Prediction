# -*- coding: utf-8 -*-
"""csci218(classification).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16YGDirfE60koUeqFfDZVCcGZkUuc3DrG

##Classification
"""

"""
Wine Classification
"""
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score
from torch.utils.data import TensorDataset, DataLoader
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from tqdm import tqdm
from google.colab import drive




# Mount Google Drive
drive.mount('/content/drive')

# Set the base path to your flowers directory in Google Drive
DRIVE_PATH = '/content/drive/MyDrive/wine'  # Change this to match your folder path

"""
Wine Classification - hypertuned
"""
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score
from torch.utils.data import TensorDataset, DataLoader
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from tqdm import tqdm

# Load datasets
red_wine_df = pd.read_csv(f"{DRIVE_PATH}/winequality-red.csv", sep=";")
white_wine_df = pd.read_csv(f"{DRIVE_PATH}/winequality-white.csv", sep=";")

# Add a column to distinguish between red and white wines
red_wine_df["wine_type"] = "red"
white_wine_df["wine_type"] = "white"

# Merge datasets
wine_df = pd.concat([red_wine_df, white_wine_df], axis=0)

# Define quality categories
def categorize_quality(q):
    if q <= 5:
        return "Bad"
    elif q == 6:
        return "Medium"
    else:
        return "Good"

# Apply categorization
wine_df["quality_category"] = wine_df["quality"].apply(categorize_quality)

# Select numeric columns
numeric_columns = wine_df.select_dtypes(include=[np.number]).columns.tolist()

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(wine_df[numeric_columns[:-1]].values)

# Encode quality categories
y = LabelEncoder().fit_transform(wine_df["quality_category"])

# Split dataset (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)

# Define model evaluation function
def evaluate_model(name, y_test, y_pred):
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    print(f"{name} Performance:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-score: {f1:.4f}\n")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Bad", "Medium", "Good"])
    plt.figure(figsize=(6,6))
    disp.plot(cmap='Blues', values_format='d')
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

# Hyperparameter tuning function with progress bar
def hyperparameter_tuning(model, param_grid, model_name):
    print(f"Tuning {model_name}...")
    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)
    grid_search.fit(X_train, y_train)
    print(f"Best parameters for {model_name}: {grid_search.best_params_}")
    return grid_search.best_estimator_

# Random Forest Model with Hyperparameter Tuning
rf_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}
rf_model = hyperparameter_tuning(RandomForestClassifier(random_state=42), rf_param_grid, "Random Forest")
y_pred_rf = rf_model.predict(X_test)

# XGBoost Model with Hyperparameter Tuning
xgb_param_grid = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}
xgb_model = hyperparameter_tuning(xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42), xgb_param_grid, "XGBoost")
y_pred_xgb = xgb_model.predict(X_test)

# K-Nearest Neighbors (KNN) Model with Hyperparameter Tuning
knn_param_grid = {'n_neighbors': [3, 5, 7]}
knn_model = hyperparameter_tuning(KNeighborsClassifier(), knn_param_grid, "KNN")
y_pred_knn = knn_model.predict(X_test)

# Neural Network (MLPClassifier) with Hyperparameter Tuning
mlp_param_grid = {'hidden_layer_sizes': [(32, 16), (64, 32)], 'max_iter': [300, 500]}
mlp_model = hyperparameter_tuning(MLPClassifier(random_state=42), mlp_param_grid, "MLPClassifier")
y_pred_mlp = mlp_model.predict(X_test)

# Evaluate models
evaluate_model("Random Forest", y_test, y_pred_rf)
evaluate_model("XGBoost", y_test, y_pred_xgb)
evaluate_model("K-Nearest Neighbors (KNN)", y_test, y_pred_knn)
evaluate_model("Neural Network (MLPClassifier)", y_test, y_pred_mlp)

import matplotlib.pyplot as plt
import seaborn as sns

# Store model accuracy scores
accuracy_results = {
    "Random Forest": accuracy_score(y_test, y_pred_rf),
    "XGBoost": accuracy_score(y_test, y_pred_xgb),
    "K-Nearest Neighbors (KNN)": accuracy_score(y_test, y_pred_knn),
    "Neural Network (MLPClassifier)": accuracy_score(y_test, y_pred_mlp),
}

# Find the best-performing model
best_model = max(accuracy_results, key=accuracy_results.get)

# Print model comparison
print("\nModel Accuracy Comparison: (hypertuned)")
for model, accuracy in accuracy_results.items():
    print(f"{model}: {accuracy:.4f}")

# Print the best model
print(f"\nBest Performing Model: {best_model} with Accuracy: {accuracy_results[best_model]:.4f}")

# Plot accuracy comparison
plt.figure(figsize=(10, 5))
sns.barplot(x=list(accuracy_results.keys()), y=list(accuracy_results.values()), palette="viridis")
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Model Accuracy Comparison")
plt.ylim(0, 1)  # Accuracy ranges from 0 to 1
plt.xticks(rotation=20)  # Rotate labels for better readability

# Annotate bars with accuracy values
for i, (model, accuracy) in enumerate(accuracy_results.items()):
    plt.text(i, accuracy + 0.01, f"{accuracy:.4f}", ha="center", fontsize=12)

plt.show()

"""
Wine Classification
"""
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score
from torch.utils.data import TensorDataset, DataLoader
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from tqdm import tqdm

# Load datasets
red_wine_df = pd.read_csv(f"{DRIVE_PATH}/winequality-red.csv", sep=";")
white_wine_df = pd.read_csv(f"{DRIVE_PATH}/winequality-white.csv", sep=";")

# Add a column to distinguish between red and white wines
red_wine_df["wine_type"] = "red"
white_wine_df["wine_type"] = "white"

# Merge datasets
wine_df = pd.concat([red_wine_df, white_wine_df], axis=0)

# Define quality categories
def categorize_quality(q):
    if q <= 5:
        return "Bad"
    elif q == 6:
        return "Medium"
    else:
        return "Good"

# Apply categorization
wine_df["quality_category"] = wine_df["quality"].apply(categorize_quality)

# Select numeric columns
numeric_columns = wine_df.select_dtypes(include=[np.number]).columns.tolist()

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(wine_df[numeric_columns[:-1]].values)

# Encode quality categories
y = LabelEncoder().fit_transform(wine_df["quality_category"])

# Split dataset (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)

# Define model evaluation function
def evaluate_model(name, y_test, y_pred):
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    print(f"{name} Performance:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-score: {f1:.4f}\n")

    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Bad", "Medium", "Good"])
    plt.figure(figsize=(6,6))
    disp.plot(cmap='Blues', values_format='d')
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

# Train models without hyperparameter tuning
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

gxgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
gxgb_model.fit(X_train, y_train)
y_pred_xgb = xgb_model.predict(X_test)

knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)
y_pred_knn = knn_model.predict(X_test)

mlp_model = MLPClassifier(random_state=42, max_iter=300)
mlp_model.fit(X_train, y_train)
y_pred_mlp = mlp_model.predict(X_test)

# Evaluate models
evaluate_model("Random Forest", y_test, y_pred_rf)
evaluate_model("XGBoost", y_test, y_pred_xgb)
evaluate_model("K-Nearest Neighbors (KNN)", y_test, y_pred_knn)
evaluate_model("Neural Network (MLPClassifier)", y_test, y_pred_mlp)

import matplotlib.pyplot as plt
import seaborn as sns

# Store model accuracy scores
accuracy_results = {
    "Random Forest": accuracy_score(y_test, y_pred_rf),
    "XGBoost": accuracy_score(y_test, y_pred_xgb),
    "K-Nearest Neighbors (KNN)": accuracy_score(y_test, y_pred_knn),
    "Neural Network (MLPClassifier)": accuracy_score(y_test, y_pred_mlp),
}

# Find the best-performing model
best_model = max(accuracy_results, key=accuracy_results.get)

# Print model comparison
print("\nModel Accuracy Comparison:")
for model, accuracy in accuracy_results.items():
    print(f"{model}: {accuracy:.4f}")

# Print the best model
print(f"\nBest Performing Model: {best_model} with Accuracy: {accuracy_results[best_model]:.4f}")

# Plot accuracy comparison
plt.figure(figsize=(10, 5))
sns.barplot(x=list(accuracy_results.keys()), y=list(accuracy_results.values()), palette="viridis")
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Model Accuracy Comparison")
plt.ylim(0, 1)  # Accuracy ranges from 0 to 1
plt.xticks(rotation=20)  # Rotate labels for better readability

# Annotate bars with accuracy values
for i, (model, accuracy) in enumerate(accuracy_results.items()):
    plt.text(i, accuracy + 0.01, f"{accuracy:.4f}", ha="center", fontsize=12)

plt.show()